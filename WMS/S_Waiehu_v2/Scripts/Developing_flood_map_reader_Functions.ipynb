{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddffd488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import sys\n",
    "import shutil\n",
    "from distutils.dir_util import copy_tree\n",
    "import distutils\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "# load up dependencies and functions, Note pyGSSHA_functions.py and  GSSHA.exe MUST be in kernal's working dir\n",
    "%run pyGSSHA_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4e90cf",
   "metadata": {},
   "source": [
    "# Functions for processing GSSHA flood \"map\" columns \n",
    "Pulling out the depth information from the Max flood gfl file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8288ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###### Function to save the max flood output file into an Arc RASTER. ######  \n",
    "\n",
    "# Note that someday I should probably pull the NumRowsCells and cols cells directly from the gfl file but whatever for now\n",
    "# And should fully abstract this and put it in the PyGSSHA functions file \n",
    "\n",
    "def WMS_Max_Flood_File_to_ASCii(gfl_file, NumRowsCells, NumCols_Cells, NumCELLS,\n",
    "                           cellsize, xll, yll, no_data_val, Save_filename, Save_FilePlace):\n",
    "    \n",
    "    NumCELLS = NumRowsCells* NumCols_Cells\n",
    "\n",
    "    arr = np.genfromtxt(gfl_file, skip_header=8, delimiter=',')    # delimit with a comma to keep it from using spaces...\n",
    "    arr = arr[:-1]   # Cut off the last row which says ENDDS\n",
    "    arr_activecells = arr[0:NumCELLS]\n",
    "    arr_datacells   =  arr[NumCELLS:]\n",
    "\n",
    "    gridmo = np.reshape(arr_datacells, (NumRowsCells, NumCols_Cells))\n",
    "\n",
    "    # plot it in python \n",
    "    fig, ax = plt.subplots(figsize=(8, 3))\n",
    "    plt.imshow(gridmo, cmap='gray')      # Plot the data using imshow with gray colormap\n",
    "\n",
    "    # Save the ASCii File \n",
    "    headerstring       = bytes('NCOLS %d\\nNROWS %d\\nXLLCENTER %f\\nYLLCENTER %f\\nCELLSIZE %f\\nNODATA_value %f\\n' % \n",
    "        (gridmo.shape[1], gridmo.shape[0], xll, yll, cellsize, no_data_val), 'UTF-8')\n",
    "    with open(os.path.join(Save_FilePlace, \"{}.asc\".format(Save_filename)),'wb') as fout:\n",
    "        fout.write(headerstring)\n",
    "        np.savetxt(fout,gridmo,'%5.2f')\n",
    "\n",
    "    # Save the projection file for ArcGIS (Projection might need to be changed depending on WMS projection?) \n",
    "    epsg = 'PROJCS[\"WGS_1984_UTM_Zone_4N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-159],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AUTHORITY[\"EPSG\",\"32604\"]],VERTCS[\"Local\",VDATUM[\"Local\"],PARAMETER[\"Direction\",1.0],UNIT[\"Meter\",1.0]]'\n",
    "    with open(os.path.join(Save_FilePlace, \"{}.prj\".format(Save_filename)), \"w\") as prj:\n",
    "        prj.write(epsg)\n",
    "        prj.close()\n",
    "        \n",
    "    print(\"Saved {}.asc at {}\".format(Save_filename, Save_FilePlace))\n",
    "    \n",
    "    return gridmo\n",
    "    \n",
    "    \n",
    "######## Input Params  ###############\n",
    "# Input Max flood grid file from WMS \n",
    "gfl_file = os.path.join('..', \"Junk\", 'Lu_testnewgrid3.gfl')\n",
    "\n",
    "# Cell geometry from the WMS model \n",
    "NumRowsCells  = 63\n",
    "NumCols_Cells = 146\n",
    "\n",
    "\n",
    "# ASCii geometry, from the Lower Left corner of the model cell \n",
    "cellsize = 50\n",
    "xll = 753486 + (cellsize/2)    # the ASC is based on the center of the Lower Left cell, whereas its easiest to see the corner\n",
    "yll  = 2312266 + (cellsize/2)  \n",
    "no_data_val = -99999\n",
    "\n",
    "Save_filename = \"testascfile11\"\n",
    "Save_FilePlace = os.path.join(\".\")\n",
    "\n",
    "# Run the to ASC function\n",
    "gridmo = WMS_Max_Flood_File_to_ASCii(gfl_file, NumRowsCells, NumCols_Cells, NumCELLS,\n",
    "                           cellsize, xll, yll, no_data_val, Save_filename, Save_FilePlace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dd0a60",
   "metadata": {},
   "source": [
    "### Function for Processing the TS depth Maps \n",
    "\n",
    "Notes: \n",
    "some key cells that flood seem to be\n",
    "- gridmo[6,135]   = the intersection at kehekili Hwy and Waiehu beach rd (one cell N of intersection)\n",
    "- gridmo[5,142] to gridmo[5,145]   = main flooding at outlet in the Maluhia church neighborhood, church is in gridmo[5,145] \n",
    "- And they key, gridmo[22,110] is the USGS stream gauge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe206f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_file  =  os.path.join('.', \"RUN\", '{}.dep'.format(PrjName))\n",
    "\n",
    "# Cell geometry from the WMS model \n",
    "NumRowsCells        = 63\n",
    "NumCols_Cells       = 146\n",
    "NumTS_to_Process    = 24\n",
    "\n",
    "Save_filename       = \"{}_dep\".format(PrjName)\n",
    "Save_FilePlace      = os.path.join(\".\", \"Figures/Dep_maps\")\n",
    "\n",
    "# ASCii geometry, from the Lower Left corner of the model cell \n",
    "cellsize = 50\n",
    "xll = 753486 + (cellsize/2)    # the ASC is based on the center of the Lower Left cell, whereas its easiest to see the corner\n",
    "yll  = 2312266 + (cellsize/2)  \n",
    "no_data_val = -99999\n",
    "\n",
    "\n",
    "def Process_TS_Flood_Files_to_ASCiis(dep_file, NumRowsCells, NumCols_Cells, \n",
    "                                     cellsize, xll, yll, no_data_val, Save_filename, Save_FilePlace, SAVE=False):\n",
    "    \n",
    "    arr = np.genfromtxt(dep_file, skip_header=7, delimiter=',', dtype=str) \n",
    "    arr = arr[:-1]   # Cut off the last row which says ENDDS\n",
    "    \n",
    "    NumCELLS = NumRowsCells* NumCols_Cells\n",
    "    \n",
    "    # This is a constant variable for each map, which uses the number of cells to determine how many rows to peel off for each timestep\n",
    "    NumRowsUnit = (NumCELLS*2)+1 # *2 is because the file contains both the mask and values every time, +1 is for the TS line  \n",
    "\n",
    "    for unit in range(0, NumTS_to_Process, 1):\n",
    "        startslice = unit * NumRowsUnit\n",
    "        endslice  = startslice + NumRowsUnit    \n",
    "        arrrr = arr[startslice:endslice]\n",
    "\n",
    "        TS = arrrr[0]\n",
    "        arr_activecells = arrrr[1:NumCELLS+1].astype(float)\n",
    "        arr_datacells   =  arrrr[NumCELLS+1:].astype(float)\n",
    "\n",
    "        gridmo = np.reshape(arr_datacells, (NumRowsCells, NumCols_Cells))\n",
    "        \n",
    "\n",
    "        ## plot it in python \n",
    "        #fig, ax = plt.subplots(figsize=(8, 3))\n",
    "        #plt.imshow(gridmo, cmap='gray')      # Plot the data using imshow with gray colormap\n",
    "\n",
    "        #print(\"{} - Flood _depth at church is {}m, at gauge is {}m\".format(TS, gridmo[5,145], gridmo[22,110]))\n",
    "        \n",
    "        if SAVE: \n",
    "            \n",
    "            Save_filename_ts = Save_filename+\"_\"+TS.split(\" \")[2][:4]\n",
    "            \n",
    "            # Save the ASCii File \n",
    "            headerstring       = bytes('NCOLS %d\\nNROWS %d\\nXLLCENTER %f\\nYLLCENTER %f\\nCELLSIZE %f\\nNODATA_value %f\\n' % \n",
    "                (gridmo.shape[1], gridmo.shape[0], xll, yll, cellsize, no_data_val), 'UTF-8')\n",
    "            with open(os.path.join(Save_FilePlace, \"{}.asc\".format(Save_filename_ts)),'wb') as fout:\n",
    "                fout.write(headerstring)\n",
    "                np.savetxt(fout,gridmo,'%5.2f')\n",
    "\n",
    "            # Save the projection file for ArcGIS (Projection might need to be changed depending on WMS projection?) \n",
    "            epsg = 'PROJCS[\"WGS_1984_UTM_Zone_4N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-159],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AUTHORITY[\"EPSG\",\"32604\"]],VERTCS[\"Local\",VDATUM[\"Local\"],PARAMETER[\"Direction\",1.0],UNIT[\"Meter\",1.0]]'\n",
    "            with open(os.path.join(Save_FilePlace, \"{}.prj\".format(Save_filename_ts)), \"w\") as prj:\n",
    "                prj.write(epsg)\n",
    "                prj.close()\n",
    "\n",
    "            #print(\"Saved {}.asc at {}\".format(Save_filename_ts, Save_FilePlace))   \n",
    "    \n",
    "    \n",
    "    \n",
    "Process_TS_Flood_Files_to_ASCiis(dep_file, NumRowsCells, NumCols_Cells,  \n",
    "                                 cellsize, xll, yll, no_data_val, Save_filename, Save_FilePlace, SAVE=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92b552",
   "metadata": {},
   "source": [
    "### Modify above to produce TS of depth at a given cell location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5aa731",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_file  = os.path.join('..', \"Junk\", 'Lu_testnewgrid3.dep')\n",
    "\n",
    "# Cell geometry from the WMS model \n",
    "NumRowsCells  = 63\n",
    "NumCols_Cells = 146\n",
    "\n",
    "# Timestep stuff\n",
    "NumTS_to_Process    = 24\n",
    "Timestep_len_mins   = 60\n",
    "Start_DateTime      = \"2023-01-20 22:06\"\n",
    "\n",
    "\n",
    "Cell_to_Extract = [22, 110]\n",
    "\n",
    "def Process_dep_maps_to_DepthTS_oneCell(dep_file, NumRowsCells, NumCols_Cells, \n",
    "                                       NumTS_to_Process, Timestep_len_mins, Start_DateTime):  \n",
    "\n",
    "    # Create containers to house data throughout the loops \n",
    "    #Depth_Timeseries_df = pd.DataFrame(columns=[\"Timestamp_txt\", \"DateTime\", \"Cell_Depth_m\"])\n",
    "    TSlist = []; DateTimeList = []; DepthList = []\n",
    "\n",
    "    NumCELLS = NumRowsCells* NumCols_Cells\n",
    "    \n",
    "    arr = np.genfromtxt(dep_file, skip_header=7, delimiter=',', dtype=str)\n",
    "    arr = arr[:-1]   # Cut off the last row which says ENDDS\n",
    "    \n",
    "    # This is a constant variable for each map, which uses the number of cells to determine how many rows to peel off for each timestep\n",
    "    NumRowsUnit = (NumCELLS*2)+1 # *2 is because the file contains both the mask and values every time, +1 is for the TS line  \n",
    "    # The start of the run in datetime \n",
    "    datetime_Start = datetime.strptime(Start_DateTime, '%Y-%m-%d %H:%M')\n",
    "    \n",
    "    # For each \"timestamped map\" this will extract the column data, throw away the \"active cells mask\" half, and give a np array of the map\n",
    "    for unit in range(0, NumTS_to_Process, 1):\n",
    "        startslice = unit * NumRowsUnit           # Start of the desired data unit\n",
    "        endslice  = startslice + NumRowsUnit      # End of desired data unit\n",
    "        arrrr = arr[startslice:endslice]          # a 1-d array containing each timesteps data\n",
    "\n",
    "        TS = arrrr[0]                             # the text of the Timestep  \n",
    "        arr_activecells = arrrr[1:NumCELLS+1].astype(float)  # These are the \"active cells mask\" part (trash)\n",
    "        arr_datacells   =  arrrr[NumCELLS+1:].astype(float)  # This is the actual data we want \n",
    "\n",
    "        gridmo = np.reshape(arr_datacells, (NumRowsCells, NumCols_Cells))  # turn 1-d silly data into useful 2d data\n",
    "        \n",
    "        # Calculate the depth at the desired cell \n",
    "        DepthAtCell = gridmo[Cell_to_Extract[0], Cell_to_Extract[1]]\n",
    "        \n",
    "        # Calculate the actual time stamp from the start time and the delta time of each step \n",
    "        \n",
    "        datetime_TS = datetime_Start + timedelta(minutes=Timestep_len_mins*unit)\n",
    "        \n",
    "        # Put the pertinant data in lists\n",
    "        TSlist.append(TS)\n",
    "        DateTimeList.append(datetime_TS)\n",
    "        DepthList.append(DepthAtCell)\n",
    "        \n",
    "    # Create dataframe of pertinant data \n",
    "    Depth_Timeseries_df = pd.DataFrame({\"Timestamp_txt\":TSlist, \"DateTime\":DateTimeList, \"Cell_Depth_m\":DepthList})\n",
    "    Depth_Timeseries_df.set_index(\"DateTime\", inplace=True)\n",
    "    return Depth_Timeseries_df\n",
    "\n",
    "\n",
    "\n",
    "# Run it!\n",
    "Depth_Timeseries_df = Process_dep_maps_to_DepthTS_oneCell(dep_file, NumRowsCells, NumCols_Cells, \n",
    "                                       NumTS_to_Process, Timestep_len_mins, Start_DateTime)\n",
    "# Plot it\n",
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "ax.plot(Depth_Timeseries_df['Cell_Depth_m'], c='b', alpha=0.4, label=\"Rainfall \")   # Plot rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07af2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25100aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_file  = os.path.join('..', \"Junk\", 'Lu_testnewgrid3.dep')\n",
    "\n",
    "# Cell geometry from the WMS model \n",
    "NumRowsCells  = 63\n",
    "NumCols_Cells = 146\n",
    "\n",
    "# Timestep stuff\n",
    "NumTS_to_Process    = 24\n",
    "Timestep_len_mins   = 60\n",
    "Start_DateTime      = \"2023-01-20 22:06\"\n",
    "\n",
    "\n",
    "Cell_to_Extract = [22, 110]\n",
    "\n",
    "def Process_dep_maps_to_DepthTS_oneCell(dep_file, Cell_to_Extract, NumRowsCells, NumCols_Cells, \n",
    "                                       NumTS_to_Process, Timestep_len_mins, Start_DateTime):  \n",
    "\n",
    "    # Create containers to house data throughout the loops \n",
    "    #Depth_Timeseries_df = pd.DataFrame(columns=[\"Timestamp_txt\", \"DateTime\", \"Cell_Depth_m\"])\n",
    "    TSlist = []; DateTimeList = []; DepthList = []\n",
    "\n",
    "    NumCELLS = NumRowsCells* NumCols_Cells\n",
    "    \n",
    "    arr = np.genfromtxt(dep_file, skip_header=7, delimiter=',', dtype=str)\n",
    "    arr = arr[:-1]   # Cut off the last row which says ENDDS\n",
    "    \n",
    "    # This is a constant variable for each map, which uses the number of cells to determine how many rows to peel off for each timestep\n",
    "    NumRowsUnit = (NumCELLS*2)+1 # *2 is because the file contains both the mask and values every time, +1 is for the TS line  \n",
    "    # The start of the run in datetime \n",
    "    datetime_Start = datetime.strptime(Start_DateTime, '%Y-%m-%d %H:%M')\n",
    "    \n",
    "    # For each \"timestamped map\" this will extract the column data, throw away the \"active cells mask\" half, and give a np array of the map\n",
    "    for unit in range(0, NumTS_to_Process, 1):\n",
    "        startslice = unit * NumRowsUnit           # Start of the desired data unit\n",
    "        endslice  = startslice + NumRowsUnit      # End of desired data unit\n",
    "        arrrr = arr[startslice:endslice]          # a 1-d array containing each timesteps data\n",
    "\n",
    "        TS = arrrr[0]                             # the text of the Timestep  \n",
    "        arr_activecells = arrrr[1:NumCELLS+1].astype(float)  # These are the \"active cells mask\" part (trash)\n",
    "        arr_datacells   =  arrrr[NumCELLS+1:].astype(float)  # This is the actual data we want \n",
    "\n",
    "        gridmo = np.reshape(arr_datacells, (NumRowsCells, NumCols_Cells))  # turn 1-d silly data into useful 2d data\n",
    "        \n",
    "        # Calculate the depth at the desired cell \n",
    "        DepthAtCell = gridmo[Cell_to_Extract[0], Cell_to_Extract[1]]\n",
    "        \n",
    "        # Calculate the actual time stamp from the start time and the delta time of each step \n",
    "        \n",
    "        datetime_TS = datetime_Start + timedelta(minutes=Timestep_len_mins*unit)\n",
    "        \n",
    "        # Put the pertinant data in lists\n",
    "        TSlist.append(TS)\n",
    "        DateTimeList.append(datetime_TS)\n",
    "        DepthList.append(DepthAtCell)\n",
    "        \n",
    "    # Create dataframe of pertinant data \n",
    "    Depth_Timeseries_df = pd.DataFrame({\"Timestamp_txt\":TSlist, \"DateTime\":DateTimeList, \"Cell_Depth_m\":DepthList})\n",
    "    Depth_Timeseries_df.set_index(\"DateTime\", inplace=True)\n",
    "    \n",
    "    return Depth_Timeseries_df\n",
    "\n",
    "\n",
    "\n",
    "# Run it!\n",
    "Depth_Timeseries_df = Process_dep_maps_to_DepthTS_oneCell(dep_file, NumRowsCells, NumCols_Cells, \n",
    "                                       NumTS_to_Process, Timestep_len_mins, Start_DateTime)\n",
    "# Plot it\n",
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "ax.plot(Depth_Timeseries_df['Cell_Depth_m'], c='b', alpha=0.4, label=\"Rainfall \")   # Plot rainfall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
